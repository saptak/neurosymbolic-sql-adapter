#!/usr/bin/env python3
"""
SQL Metrics Evaluation Module

This module provides comprehensive evaluation metrics for SQL query quality,
including syntax validation, semantic correctness, and execution validation.
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import difflib

try:
    import sqlparse
    from sqlparse import sql, tokens, keywords
    SQLPARSE_AVAILABLE = True
except ImportError:
    SQLPARSE_AVAILABLE = False

@dataclass
class SQLEvaluationResult:
    """Result container for SQL evaluation"""
    
    syntax_accuracy: float
    semantic_correctness: float
    structural_similarity: float
    keyword_accuracy: float
    table_reference_accuracy: float
    column_reference_accuracy: float
    constraint_compliance: float
    overall_score: float
    
    # Detailed analysis
    syntax_errors: List[str]
    semantic_issues: List[str]
    missing_keywords: List[str]
    extra_keywords: List[str]
    missing_tables: List[str]
    extra_tables: List[str]
    missing_columns: List[str]
    extra_columns: List[str]

class SQLMetrics:
    """
    Comprehensive SQL evaluation metrics
    
    Provides multiple evaluation approaches:
    1. Syntax validation using sqlparse
    2. Semantic analysis through structure comparison
    3. Keyword and clause analysis
    4. Table and column reference validation
    5. Query complexity assessment
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize SQL metrics evaluator
        
        Args:
            config: Configuration including:
                - enable_syntax_validation: Whether to validate SQL syntax
                - enable_semantic_analysis: Whether to perform semantic analysis
                - enable_execution_validation: Whether to validate through execution
                - strict_mode: Whether to use strict evaluation criteria
        """
        self.config = config
        self.logger = self._setup_logging()
        
        # Configuration
        self.enable_syntax = config.get('enable_syntax_validation', True)
        self.enable_semantic = config.get('enable_semantic_analysis', True)
        self.enable_execution = config.get('enable_execution_validation', False)
        self.strict_mode = config.get('strict_mode', False)
        
        # SQL parsing capabilities
        self.sqlparse_available = SQLPARSE_AVAILABLE
        if not self.sqlparse_available:
            self.logger.warning("sqlparse not available - syntax validation will be limited")
        
        self.logger.info("SQL metrics evaluator initialized")
    
    def _setup_logging(self) -> logging.Logger:
        """Setup logging for SQL metrics"""
        logger = logging.getLogger("sql_metrics")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def evaluate_sql(
        self, 
        generated_sql: str, 
        expected_sql: str, 
        schema: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Comprehensive SQL evaluation
        
        Args:
            generated_sql: SQL query generated by the model
            expected_sql: Expected/reference SQL query
            schema: Optional schema information for validation
            
        Returns:
            Dictionary containing all evaluation metrics
        """
        
        # Initialize result containers
        syntax_errors = []
        semantic_issues = []
        
        # 1. Syntax validation
        if self.enable_syntax:
            syntax_accuracy, syntax_errs = self._evaluate_syntax(generated_sql)
            syntax_errors.extend(syntax_errs)
        else:
            syntax_accuracy = 1.0
        
        # 2. Semantic analysis
        if self.enable_semantic:
            semantic_results = self._evaluate_semantics(generated_sql, expected_sql, schema)
            semantic_correctness = semantic_results['semantic_correctness']
            semantic_issues = semantic_results['semantic_issues']
        else:
            semantic_correctness = 1.0
        
        # 3. Structural similarity
        structural_similarity = self._calculate_structural_similarity(generated_sql, expected_sql)
        
        # 4. Keyword analysis
        keyword_results = self._analyze_keywords(generated_sql, expected_sql)
        
        # 5. Table and column analysis
        reference_results = self._analyze_references(generated_sql, expected_sql, schema)
        
        # 6. Constraint compliance (if schema provided)
        if schema:
            constraint_compliance = self._evaluate_constraint_compliance(generated_sql, schema)
        else:
            constraint_compliance = 1.0
        
        # Calculate overall score
        overall_score = self._calculate_overall_score({
            'syntax_accuracy': syntax_accuracy,
            'semantic_correctness': semantic_correctness,
            'structural_similarity': structural_similarity,
            'keyword_accuracy': keyword_results['keyword_accuracy'],
            'table_reference_accuracy': reference_results['table_accuracy'],
            'column_reference_accuracy': reference_results['column_accuracy'],
            'constraint_compliance': constraint_compliance
        })
        
        # Create comprehensive result
        result = SQLEvaluationResult(
            syntax_accuracy=syntax_accuracy,
            semantic_correctness=semantic_correctness,
            structural_similarity=structural_similarity,
            keyword_accuracy=keyword_results['keyword_accuracy'],
            table_reference_accuracy=reference_results['table_accuracy'],
            column_reference_accuracy=reference_results['column_accuracy'],
            constraint_compliance=constraint_compliance,
            overall_score=overall_score,
            
            # Detailed analysis
            syntax_errors=syntax_errors,
            semantic_issues=semantic_issues,
            missing_keywords=keyword_results['missing_keywords'],
            extra_keywords=keyword_results['extra_keywords'],
            missing_tables=reference_results['missing_tables'],
            extra_tables=reference_results['extra_tables'],
            missing_columns=reference_results['missing_columns'],
            extra_columns=reference_results['extra_columns']
        )
        
        return self._result_to_dict(result)
    
    def _evaluate_syntax(self, sql: str) -> Tuple[float, List[str]]:
        """Evaluate SQL syntax correctness"""
        
        errors = []
        
        if not sql or not sql.strip():
            return 0.0, ["Empty SQL query"]
        
        # Basic syntax checks
        sql_clean = sql.strip()
        
        # Check for basic SQL structure
        if not any(keyword in sql_clean.upper() for keyword in ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER']):
            errors.append("No valid SQL statement keyword found")
        
        # Check for balanced parentheses
        if sql_clean.count('(') != sql_clean.count(')'):
            errors.append("Unbalanced parentheses")
        
        # Check for balanced quotes
        single_quotes = sql_clean.count("'")
        double_quotes = sql_clean.count('"')
        if single_quotes % 2 != 0:
            errors.append("Unbalanced single quotes")
        if double_quotes % 2 != 0:
            errors.append("Unbalanced double quotes")
        
        # Advanced syntax validation with sqlparse
        if self.sqlparse_available:
            try:
                parsed = sqlparse.parse(sql_clean)
                if not parsed:
                    errors.append("Failed to parse SQL")
                else:
                    # Check for parsing errors
                    for statement in parsed:
                        if not self._is_valid_statement(statement):
                            errors.append("Invalid SQL statement structure")
            except Exception as e:
                errors.append(f"SQL parsing error: {str(e)}")
        
        # Calculate accuracy
        if not errors:
            accuracy = 1.0
        else:
            # Penalize based on number and severity of errors
            severity_penalty = min(len(errors) * 0.2, 0.8)
            accuracy = max(0.0, 1.0 - severity_penalty)
        
        return accuracy, errors
    
    def _is_valid_statement(self, statement) -> bool:
        """Check if parsed statement is valid"""
        
        if not statement.tokens:
            return False
        
        # Look for valid SQL keywords
        has_valid_keyword = False
        for token in statement.tokens:
            if token.ttype is tokens.Keyword and token.value.upper() in {
                'SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER'
            }:
                has_valid_keyword = True
                break
        
        return has_valid_keyword
    
    def _evaluate_semantics(
        self, 
        generated_sql: str, 
        expected_sql: str, 
        schema: Optional[str] = None
    ) -> Dict[str, Any]:
        """Evaluate semantic correctness of SQL"""
        
        semantic_issues = []
        
        # Parse both queries for comparison
        generated_structure = self._parse_sql_structure(generated_sql)
        expected_structure = self._parse_sql_structure(expected_sql)
        
        # Compare query types
        if generated_structure['query_type'] != expected_structure['query_type']:
            semantic_issues.append(f"Query type mismatch: expected {expected_structure['query_type']}, got {generated_structure['query_type']}")
        
        # Compare main clauses
        clause_comparison = self._compare_clauses(generated_structure, expected_structure)
        semantic_issues.extend(clause_comparison['issues'])
        
        # Compare logical structure
        logic_comparison = self._compare_query_logic(generated_sql, expected_sql)
        semantic_issues.extend(logic_comparison['issues'])
        
        # Calculate semantic correctness
        if not semantic_issues:
            semantic_correctness = 1.0
        else:
            # Penalize based on severity of semantic issues
            penalty = min(len(semantic_issues) * 0.15, 0.75)
            semantic_correctness = max(0.0, 1.0 - penalty)
        
        return {
            'semantic_correctness': semantic_correctness,
            'semantic_issues': semantic_issues,
            'generated_structure': generated_structure,
            'expected_structure': expected_structure
        }
    
    def _parse_sql_structure(self, sql: str) -> Dict[str, Any]:
        """Parse SQL into structural components"""
        
        sql_upper = sql.upper()
        
        # Determine query type
        if 'SELECT' in sql_upper:
            query_type = 'SELECT'
        elif 'INSERT' in sql_upper:
            query_type = 'INSERT'
        elif 'UPDATE' in sql_upper:
            query_type = 'UPDATE'
        elif 'DELETE' in sql_upper:
            query_type = 'DELETE'
        else:
            query_type = 'UNKNOWN'
        
        # Extract key clauses
        clauses = {
            'SELECT': self._extract_clause(sql, 'SELECT'),
            'FROM': self._extract_clause(sql, 'FROM'),
            'WHERE': self._extract_clause(sql, 'WHERE'),
            'GROUP BY': self._extract_clause(sql, 'GROUP BY'),
            'HAVING': self._extract_clause(sql, 'HAVING'),
            'ORDER BY': self._extract_clause(sql, 'ORDER BY'),
            'LIMIT': self._extract_clause(sql, 'LIMIT'),
            'JOIN': self._extract_joins(sql)
        }
        
        # Extract tables and columns
        tables = self._extract_tables(sql)
        columns = self._extract_columns(sql)
        
        return {
            'query_type': query_type,
            'clauses': clauses,
            'tables': tables,
            'columns': columns,
            'has_joins': bool(clauses['JOIN']),
            'has_aggregation': self._has_aggregation(sql),
            'has_subqueries': self._has_subqueries(sql)
        }
    
    def _extract_clause(self, sql: str, clause_name: str) -> Optional[str]:
        """Extract specific SQL clause"""
        
        pattern = rf'\b{clause_name}\s+([^;]+?)(?:\s+(?:FROM|WHERE|GROUP BY|HAVING|ORDER BY|LIMIT|$))'
        match = re.search(pattern, sql, re.IGNORECASE | re.DOTALL)
        
        if match:
            return match.group(1).strip()
        return None
    
    def _extract_joins(self, sql: str) -> List[str]:
        """Extract JOIN clauses"""
        
        joins = []
        join_pattern = r'((?:INNER|LEFT|RIGHT|FULL|OUTER)?\s*JOIN\s+[^;]+?)(?=\s+(?:WHERE|GROUP|HAVING|ORDER|LIMIT|$))'
        
        matches = re.finditer(join_pattern, sql, re.IGNORECASE | re.DOTALL)
        for match in matches:
            joins.append(match.group(1).strip())
        
        return joins
    
    def _extract_tables(self, sql: str) -> List[str]:
        """Extract table names from SQL"""
        
        tables = []
        
        # Extract from FROM clause
        from_match = re.search(r'\bFROM\s+([^;]+?)(?:\s+(?:WHERE|GROUP|HAVING|ORDER|LIMIT|$))', sql, re.IGNORECASE | re.DOTALL)
        if from_match:
            from_clause = from_match.group(1)
            # Simple table extraction (could be enhanced)
            table_matches = re.findall(r'\b(\w+)(?:\s+(?:AS\s+)?\w+)?', from_clause)
            tables.extend(table_matches)
        
        # Extract from JOIN clauses
        join_matches = re.finditer(r'JOIN\s+(\w+)', sql, re.IGNORECASE)
        for match in join_matches:
            tables.append(match.group(1))
        
        return list(set(tables))  # Remove duplicates
    
    def _extract_columns(self, sql: str) -> List[str]:
        """Extract column names from SQL"""
        
        columns = []
        
        # Extract from SELECT clause
        select_match = re.search(r'\bSELECT\s+([^;]+?)(?:\s+FROM)', sql, re.IGNORECASE | re.DOTALL)
        if select_match:
            select_clause = select_match.group(1)
            if '*' not in select_clause:
                # Simple column extraction
                column_matches = re.findall(r'\b(\w+(?:\.\w+)?)', select_clause)
                columns.extend(column_matches)
        
        return columns
    
    def _has_aggregation(self, sql: str) -> bool:
        """Check if SQL has aggregation functions"""
        
        agg_functions = ['COUNT', 'SUM', 'AVG', 'MIN', 'MAX', 'GROUP_CONCAT']
        sql_upper = sql.upper()
        
        return any(func in sql_upper for func in agg_functions) or 'GROUP BY' in sql_upper
    
    def _has_subqueries(self, sql: str) -> bool:
        """Check if SQL has subqueries"""
        
        # Simple check for nested SELECT
        select_count = sql.upper().count('SELECT')
        return select_count > 1
    
    def _compare_clauses(self, generated: Dict, expected: Dict) -> Dict[str, Any]:
        """Compare SQL clauses between generated and expected"""
        
        issues = []
        
        for clause_name in ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'ORDER BY']:
            gen_clause = generated['clauses'].get(clause_name)
            exp_clause = expected['clauses'].get(clause_name)
            
            if exp_clause and not gen_clause:
                issues.append(f"Missing {clause_name} clause")
            elif not exp_clause and gen_clause:
                issues.append(f"Unexpected {clause_name} clause")
        
        # Check for structural differences
        if generated['has_joins'] != expected['has_joins']:
            issues.append("JOIN usage mismatch")
        
        if generated['has_aggregation'] != expected['has_aggregation']:
            issues.append("Aggregation usage mismatch")
        
        if generated['has_subqueries'] != expected['has_subqueries']:
            issues.append("Subquery usage mismatch")
        
        return {'issues': issues}
    
    def _compare_query_logic(self, generated_sql: str, expected_sql: str) -> Dict[str, Any]:
        """Compare logical structure of queries"""
        
        issues = []
        
        # Normalize queries for comparison
        gen_normalized = self._normalize_sql(generated_sql)
        exp_normalized = self._normalize_sql(expected_sql)
        
        # Compare normalized structure
        if gen_normalized != exp_normalized:
            # Calculate similarity
            similarity = difflib.SequenceMatcher(None, gen_normalized, exp_normalized).ratio()
            if similarity < 0.8:  # Threshold for significant differences
                issues.append(f"Significant logical structure differences (similarity: {similarity:.2f})")
        
        return {'issues': issues}
    
    def _normalize_sql(self, sql: str) -> str:
        """Normalize SQL for comparison"""
        
        # Basic normalization
        normalized = sql.upper()
        normalized = re.sub(r'\s+', ' ', normalized)  # Collapse whitespace
        normalized = re.sub(r'["\']([^"\']*)["\']', r"'\1'", normalized)  # Normalize quotes
        normalized = normalized.strip()
        
        return normalized
    
    def _calculate_structural_similarity(self, generated_sql: str, expected_sql: str) -> float:
        """Calculate structural similarity between queries"""
        
        gen_normalized = self._normalize_sql(generated_sql)
        exp_normalized = self._normalize_sql(expected_sql)
        
        return difflib.SequenceMatcher(None, gen_normalized, exp_normalized).ratio()
    
    def _analyze_keywords(self, generated_sql: str, expected_sql: str) -> Dict[str, Any]:
        """Analyze SQL keyword usage"""
        
        # Extract keywords
        gen_keywords = self._extract_keywords(generated_sql)
        exp_keywords = self._extract_keywords(expected_sql)
        
        # Compare keywords
        missing_keywords = list(set(exp_keywords) - set(gen_keywords))
        extra_keywords = list(set(gen_keywords) - set(exp_keywords))
        
        # Calculate accuracy
        if not exp_keywords:
            keyword_accuracy = 1.0
        else:
            correct_keywords = len(set(gen_keywords) & set(exp_keywords))
            keyword_accuracy = correct_keywords / len(exp_keywords)
        
        return {
            'keyword_accuracy': keyword_accuracy,
            'missing_keywords': missing_keywords,
            'extra_keywords': extra_keywords,
            'generated_keywords': gen_keywords,
            'expected_keywords': exp_keywords
        }
    
    def _extract_keywords(self, sql: str) -> List[str]:
        """Extract SQL keywords from query"""
        
        sql_keywords = [
            'SELECT', 'FROM', 'WHERE', 'JOIN', 'INNER', 'LEFT', 'RIGHT', 'OUTER',
            'GROUP BY', 'HAVING', 'ORDER BY', 'LIMIT', 'OFFSET', 'DISTINCT',
            'COUNT', 'SUM', 'AVG', 'MAX', 'MIN', 'AND', 'OR', 'NOT', 'IN',
            'EXISTS', 'BETWEEN', 'LIKE', 'IS', 'NULL', 'AS', 'ON', 'UNION',
            'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER', 'INDEX'
        ]
        
        found_keywords = []
        sql_upper = sql.upper()
        
        for keyword in sql_keywords:
            if keyword in sql_upper:
                found_keywords.append(keyword)
        
        return found_keywords
    
    def _analyze_references(
        self, 
        generated_sql: str, 
        expected_sql: str, 
        schema: Optional[str] = None
    ) -> Dict[str, Any]:
        """Analyze table and column references"""
        
        # Extract references
        gen_tables = self._extract_tables(generated_sql)
        exp_tables = self._extract_tables(expected_sql)
        gen_columns = self._extract_columns(generated_sql)
        exp_columns = self._extract_columns(expected_sql)
        
        # Compare tables
        missing_tables = list(set(exp_tables) - set(gen_tables))
        extra_tables = list(set(gen_tables) - set(exp_tables))
        
        # Compare columns
        missing_columns = list(set(exp_columns) - set(gen_columns))
        extra_columns = list(set(gen_columns) - set(exp_columns))
        
        # Calculate accuracies
        if not exp_tables:
            table_accuracy = 1.0
        else:
            correct_tables = len(set(gen_tables) & set(exp_tables))
            table_accuracy = correct_tables / len(exp_tables)
        
        if not exp_columns:
            column_accuracy = 1.0
        else:
            correct_columns = len(set(gen_columns) & set(exp_columns))
            column_accuracy = correct_columns / len(exp_columns)
        
        return {
            'table_accuracy': table_accuracy,
            'column_accuracy': column_accuracy,
            'missing_tables': missing_tables,
            'extra_tables': extra_tables,
            'missing_columns': missing_columns,
            'extra_columns': extra_columns
        }
    
    def _evaluate_constraint_compliance(self, sql: str, schema: str) -> float:
        """Evaluate compliance with schema constraints"""
        
        # Basic constraint checking
        # This is a simplified implementation - could be enhanced with actual schema parsing
        
        compliance_score = 1.0
        
        # Check if referenced tables exist in schema
        tables = self._extract_tables(sql)
        schema_upper = schema.upper()
        
        for table in tables:
            if table.upper() not in schema_upper:
                compliance_score -= 0.2  # Penalty for unknown table
        
        return max(0.0, compliance_score)
    
    def _calculate_overall_score(self, metrics: Dict[str, float]) -> float:
        """Calculate weighted overall score"""
        
        weights = {
            'syntax_accuracy': 0.25,
            'semantic_correctness': 0.30,
            'structural_similarity': 0.20,
            'keyword_accuracy': 0.10,
            'table_reference_accuracy': 0.10,
            'column_reference_accuracy': 0.05
        }
        
        overall_score = 0.0
        total_weight = 0.0
        
        for metric, weight in weights.items():
            if metric in metrics:
                overall_score += metrics[metric] * weight
                total_weight += weight
        
        return overall_score / total_weight if total_weight > 0 else 0.0
    
    def _result_to_dict(self, result: SQLEvaluationResult) -> Dict[str, Any]:
        """Convert result to dictionary"""
        
        return {
            'syntax_accuracy': result.syntax_accuracy,
            'semantic_correctness': result.semantic_correctness,
            'structural_similarity': result.structural_similarity,
            'keyword_accuracy': result.keyword_accuracy,
            'table_reference_accuracy': result.table_reference_accuracy,
            'column_reference_accuracy': result.column_reference_accuracy,
            'constraint_compliance': result.constraint_compliance,
            'overall_score': result.overall_score,
            
            'detailed_analysis': {
                'syntax_errors': result.syntax_errors,
                'semantic_issues': result.semantic_issues,
                'missing_keywords': result.missing_keywords,
                'extra_keywords': result.extra_keywords,
                'missing_tables': result.missing_tables,
                'extra_tables': result.extra_tables,
                'missing_columns': result.missing_columns,
                'extra_columns': result.extra_columns
            }
        }
    
    def aggregate_results(self, results: List[Dict[str, Any]]) -> Dict[str, float]:
        """Aggregate results from multiple SQL evaluations"""
        
        if not results:
            return {}
        
        # Calculate averages
        metrics = [
            'syntax_accuracy', 'semantic_correctness', 'structural_similarity',
            'keyword_accuracy', 'table_reference_accuracy', 'column_reference_accuracy',
            'constraint_compliance', 'overall_score'
        ]
        
        aggregated = {}
        
        for metric in metrics:
            values = [r.get(metric, 0.0) for r in results if metric in r]
            if values:
                aggregated[metric] = sum(values) / len(values)
            else:
                aggregated[metric] = 0.0
        
        # Additional aggregate metrics
        aggregated['total_evaluations'] = len(results)
        aggregated['high_quality_queries'] = sum(1 for r in results if r.get('overall_score', 0.0) > 0.8)
        aggregated['high_quality_rate'] = aggregated['high_quality_queries'] / len(results) if results else 0.0
        
        return aggregated